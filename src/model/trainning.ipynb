{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Features:**\n",
    "- Years of Experience: The number of years of experience required for the job, which has been processed to be a numeric value.\n",
    "- Role: The job role (e.g., Developer, Senior, Manager). This is one-hot encoded into multiple binary columns, one for each role type.\n",
    "- Additional features (optional): Other features in your dataset can be included, such as the company, job title, etc. But in your current example, only Years of Experience and Role are used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmtho\\AppData\\Local\\Temp\\ipykernel_18912\\2078840633.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['min_salary'].fillna(0, inplace=True)\n",
      "C:\\Users\\nmtho\\AppData\\Local\\Temp\\ipykernel_18912\\2078840633.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['max_salary'].fillna(data['min_salary'], inplace=True)\n",
      "C:\\Users\\nmtho\\AppData\\Local\\Temp\\ipykernel_18912\\2078840633.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Years of Experience'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0001790240431042898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"D:\\\\Work\\\\Projects\\\\Intro2DS-ITJobTrendAnalysis\\\\data\\\\processed\\\\11-2024\\\\merged_data.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna({\"Company\": \"Unknown\", \"Salary Range\": \"Negotiable\"}, inplace=True)\n",
    "\n",
    "# Split salary range\n",
    "data[['min_salary', 'max_salary']] = data['Salary Range'].str.extract(r'(\\d+\\.?\\d*)-(\\d+\\.?\\d*)')\n",
    "data[['min_salary', 'max_salary']] = data[['min_salary', 'max_salary']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing salary values\n",
    "data['min_salary'].fillna(0, inplace=True)\n",
    "data['max_salary'].fillna(data['min_salary'], inplace=True)\n",
    "\n",
    "# Process Years of Experience\n",
    "data['Years of Experience'] = data['Years of Experience'].str.extract(r'(\\d+)')  # Extract the first number\n",
    "data['Years of Experience'] = pd.to_numeric(data['Years of Experience'], errors='coerce')  # Convert to numeric\n",
    "data['Years of Experience'].fillna(0, inplace=True)\n",
    "\n",
    "# One-Hot Encode 'Job Level' or 'Experience Level' if it's a string (e.g., 'Junior', 'Mid', 'Senior')\n",
    "if 'Experience Level' in data.columns:  # Example: 'Experience Level' is a possible column for such data\n",
    "    experience_encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_experience = experience_encoder.fit_transform(data[['Experience Level']])\n",
    "    experience_columns = experience_encoder.get_feature_names_out(['Experience Level'])\n",
    "    encoded_experience_df = pd.DataFrame(encoded_experience, columns=experience_columns, index=data.index)\n",
    "    data = pd.concat([data, encoded_experience_df], axis=1)\n",
    "\n",
    "# One-Hot Encode 'Role' (if it's categorical)\n",
    "role_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_roles = role_encoder.fit_transform(data[['Role']])\n",
    "role_columns = role_encoder.get_feature_names_out(['Role'])\n",
    "encoded_roles_df = pd.DataFrame(encoded_roles, columns=role_columns, index=data.index)\n",
    "data = pd.concat([data, encoded_roles_df], axis=1)\n",
    "\n",
    "# Drop original 'Role' column\n",
    "data = data.drop(columns=['Role'])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "data[['Years of Experience', 'min_salary', 'max_salary']] = scaler.fit_transform(data[['Years of Experience', 'min_salary', 'max_salary']])\n",
    "\n",
    "# Prepare training and test sets\n",
    "X = data.drop(columns=['Job Title','Company', 'Salary Range','Source Platform', 'max_salary', 'Level', 'Location', 'Required Skills'])  # Drop unnecessary columns\n",
    "y = data['min_salary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and evaluate model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Projects\\Intro2DS-ITJobTrendAnalysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but RandomForestRegressor is expecting 38 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m sample_data_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(sample_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYears of Experience\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m predicted_salary \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Output the prediction\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Minimum Salary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_salary[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Work\\Projects\\Intro2DS-ITJobTrendAnalysis\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1065\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1063\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32md:\\Work\\Projects\\Intro2DS-ITJobTrendAnalysis\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Work\\Projects\\Intro2DS-ITJobTrendAnalysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\Work\\Projects\\Intro2DS-ITJobTrendAnalysis\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but RandomForestRegressor is expecting 38 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Sample input (you can replace this with actual input data)\n",
    "sample_data = pd.DataFrame({\n",
    "    'Years of Experience': [3],\n",
    "    'Experience Level_Entry': [0],  # Assuming you already have encoded values for experience level\n",
    "    'Experience Level_Mid': [1],\n",
    "    'Experience Level_Senior': [0],\n",
    "    'Role_Data Analyst': [1],  # Assuming you have one-hot encoded Role\n",
    "    # Add all the other columns that were used in the model's training process here\n",
    "})\n",
    "\n",
    "# Ensure the input features are scaled using the same scaler as the training data\n",
    "scaler = StandardScaler()\n",
    "sample_data_scaled = scaler.fit_transform(sample_data[['Years of Experience']])\n",
    "\n",
    "# Make the prediction\n",
    "predicted_salary = model.predict(sample_data_scaled)\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"Predicted Minimum Salary: {predicted_salary[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
